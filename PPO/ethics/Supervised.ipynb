{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import glob\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EthicsDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        outputs = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "        }\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            outputs['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(category, file_type):\n",
    "    if category == 'utilitarianism':\n",
    "        prefix = 'util'\n",
    "    elif category == \"commonsense\":\n",
    "        prefix = \"cm\"\n",
    "    else:\n",
    "        prefix = category\n",
    "    \n",
    "    file_path = os.path.join(category, f\"{prefix}_{file_type}.csv\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Different categories of datasets have different structures, process them separately\n",
    "    if category == 'deontology':\n",
    "        texts = df['scenario'].astype(str) + ' ' + df['excuse'].astype(str)\n",
    "        if 'label' in df.columns:\n",
    "            labels = df['label'].values\n",
    "        else:\n",
    "            labels = None\n",
    "    elif category == 'utilitarianism':\n",
    "        columns = df.columns.tolist()\n",
    "        texts = df[columns[0]].values\n",
    "        # For data without labels, return None\n",
    "        labels = None\n",
    "    else:\n",
    "        if 'label' in df.columns:\n",
    "            labels = df['label'].values\n",
    "            texts = df.iloc[:, 1:].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).values\n",
    "        else:\n",
    "            labels = None\n",
    "            texts = df.iloc[:, 0:].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1).values\n",
    "    \n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            true_labels.extend(labels.cpu().tolist())\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='macro')\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, epochs=3):\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "    \n",
    "    # Total training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    \n",
    "    # Create learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Starting Epoch {epoch+1}/{epochs}')\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f'Average training loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "        # Evaluate model\n",
    "        print('Evaluating on validation set...')\n",
    "        accuracy, precision, recall, f1 = evaluate_model(model, val_dataloader)\n",
    "        print(f'Validation accuracy: {accuracy:.4f}')\n",
    "        print(f'Validation precision: {precision:.4f}')\n",
    "        print(f'Validation recall: {recall:.4f}')\n",
    "        print(f'Validation F1 score: {f1:.4f}')\n",
    "        print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    categories = [folder for folder in os.listdir() if os.path.isdir(folder) and folder != 'utilitarianism']\n",
    "    categories.remove('.ipynb_checkpoints')\n",
    "    print(f\"Found the following categories: {categories}\")\n",
    "    \n",
    "    all_train_texts = []\n",
    "    all_train_labels = []\n",
    "    \n",
    "    for category in categories:\n",
    "        print(f\"Processing training data for category: {category}\")\n",
    "        \n",
    "        train_texts, train_labels = load_data(category, 'train')\n",
    "        all_train_texts.extend(train_texts)\n",
    "        all_train_labels.extend(train_labels)\n",
    "    \n",
    "    train_dataset = EthicsDataset(all_train_texts, all_train_labels, tokenizer)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    val_texts, val_labels = load_data(categories[0], 'test')\n",
    "    val_dataset = EthicsDataset(val_texts, val_labels, tokenizer)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=2,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    model = train_model(model, train_dataloader, val_dataloader, epochs=3)\n",
    "    model_save_path = 'ethics_model'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    print(f'Model saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYT\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following categories: ['commonsense', 'deontology', 'justice', 'virtue']\n",
      "Processing training data for category: commonsense\n",
      "Processing training data for category: deontology\n",
      "Processing training data for category: justice\n",
      "Processing training data for category: virtue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LYT\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\LYT\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/3\n",
      "Average training loss: 0.3649\n",
      "Evaluating on validation set...\n",
      "Validation accuracy: 0.7743\n",
      "Validation precision: 0.7789\n",
      "Validation recall: 0.7782\n",
      "Validation F1 score: 0.7742\n",
      "\n",
      "Starting Epoch 2/3\n",
      "Average training loss: 0.2203\n",
      "Evaluating on validation set...\n",
      "Validation accuracy: 0.8167\n",
      "Validation precision: 0.8164\n",
      "Validation recall: 0.8177\n",
      "Validation F1 score: 0.8165\n",
      "\n",
      "Starting Epoch 3/3\n",
      "Average training loss: 0.1443\n",
      "Evaluating on validation set...\n",
      "Validation accuracy: 0.8386\n",
      "Validation precision: 0.8379\n",
      "Validation recall: 0.8380\n",
      "Validation F1 score: 0.8380\n",
      "\n",
      "Model saved to ethics_model\n"
     ]
    }
   ],
   "source": [
    "train_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluating on each category separately =====\n",
      "\n",
      "----- Category: commonsense -----\n",
      "Evaluating final model on commonsense regular test set...\n",
      "commonsense Test accuracy: 0.8386\n",
      "commonsense Test precision: 0.8379\n",
      "commonsense Test recall: 0.8380\n",
      "commonsense Test F1 score: 0.8380\n",
      "\n",
      "Evaluating final model on commonsense hard test set...\n",
      "commonsense Hard test accuracy: 0.4818\n",
      "commonsense Hard test precision: 0.4843\n",
      "commonsense Hard test recall: 0.4844\n",
      "commonsense Hard test F1 score: 0.4816\n",
      "\n",
      "----- Category: deontology -----\n",
      "Evaluating final model on deontology regular test set...\n",
      "deontology Test accuracy: 0.8142\n",
      "deontology Test precision: 0.8168\n",
      "deontology Test recall: 0.8145\n",
      "deontology Test F1 score: 0.8140\n",
      "\n",
      "Evaluating final model on deontology hard test set...\n",
      "deontology Hard test accuracy: 0.6620\n",
      "deontology Hard test precision: 0.6709\n",
      "deontology Hard test recall: 0.6624\n",
      "deontology Hard test F1 score: 0.6579\n",
      "\n",
      "----- Category: justice -----\n",
      "Evaluating final model on justice regular test set...\n",
      "justice Test accuracy: 0.7822\n",
      "justice Test precision: 0.7883\n",
      "justice Test recall: 0.7821\n",
      "justice Test F1 score: 0.7810\n",
      "\n",
      "Evaluating final model on justice hard test set...\n",
      "justice Hard test accuracy: 0.6174\n",
      "justice Hard test precision: 0.6223\n",
      "justice Hard test recall: 0.6146\n",
      "justice Hard test F1 score: 0.6100\n",
      "\n",
      "----- Category: virtue -----\n",
      "Evaluating final model on virtue regular test set...\n",
      "virtue Test accuracy: 0.8420\n",
      "virtue Test precision: 0.7562\n",
      "virtue Test recall: 0.7185\n",
      "virtue Test F1 score: 0.7341\n",
      "\n",
      "Evaluating final model on virtue hard test set...\n",
      "virtue Hard test accuracy: 0.7247\n",
      "virtue Hard test precision: 0.5372\n",
      "virtue Hard test recall: 0.5310\n",
      "virtue Hard test F1 score: 0.5322\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('ethics_model')\n",
    "print(\"===== Evaluating on each category separately =====\")\n",
    "model = BertForSequenceClassification.from_pretrained('ethics_model')\n",
    "model.to(device)\n",
    "\n",
    "categories = [folder for folder in os.listdir() if os.path.isdir(folder) and folder != 'utilitarianism']\n",
    "categories.remove('.ipynb_checkpoints')\n",
    "categories.remove('ethics_model')\n",
    "\n",
    "for category in categories:\n",
    "        print(f\"\\n----- Category: {category} -----\")\n",
    "        \n",
    "        # Regular test set evaluation\n",
    "        print(f'Evaluating final model on {category} regular test set...')\n",
    "        test_texts, test_labels = load_data(category, 'test')\n",
    "        test_dataset = EthicsDataset(test_texts, test_labels, tokenizer)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        test_accuracy, test_precision, test_recall, test_f1 = evaluate_model(model, test_dataloader)\n",
    "        print(f'{category} Test accuracy: {test_accuracy:.4f}')\n",
    "        print(f'{category} Test precision: {test_precision:.4f}')\n",
    "        print(f'{category} Test recall: {test_recall:.4f}')\n",
    "        print(f'{category} Test F1 score: {test_f1:.4f}')\n",
    "        \n",
    "        print(f'\\nEvaluating final model on {category} hard test set...')\n",
    "        test_hard_texts, test_hard_labels = load_data(category, 'test_hard')\n",
    "        test_hard_dataset = EthicsDataset(test_hard_texts, test_hard_labels, tokenizer)\n",
    "        test_hard_dataloader = DataLoader(test_hard_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        test_hard_accuracy, test_hard_precision, test_hard_recall, test_hard_f1 = evaluate_model(model, test_hard_dataloader)\n",
    "        print(f'{category} Hard test accuracy: {test_hard_accuracy:.4f}')\n",
    "        print(f'{category} Hard test precision: {test_hard_precision:.4f}')\n",
    "        print(f'{category} Hard test recall: {test_hard_recall:.4f}')\n",
    "        print(f'{category} Hard test F1 score: {test_hard_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07fbe3966d9943cc8bb0df6bfcee7658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e95fa26affa416abad4342d2495376b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43e71c64c5e24827af391a46dadb2dc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07fbe3966d9943cc8bb0df6bfcee7658",
      "max": 437958648,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e95fa26affa416abad4342d2495376b",
      "value": 437958648
     }
    },
    "4e9b80fb0ed94718b52ef99fc95fa090": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87488af28fdd4452891eeb5a3f116e04": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aef3514475a54e5485aea6d9d23f5102",
      "placeholder": "​",
      "style": "IPY_MODEL_d1fd3455cc1b4cfbba80191b71aef6c6",
      "value": " 438M/438M [00:20&lt;00:00, 28.4MB/s]"
     }
    },
    "8823feae77cb43a38197073de223f651": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1f8c070c94f4cfca85ca0f290886d8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e305ad027c664c7185e145cf1413f4d4",
       "IPY_MODEL_43e71c64c5e24827af391a46dadb2dc6",
       "IPY_MODEL_87488af28fdd4452891eeb5a3f116e04"
      ],
      "layout": "IPY_MODEL_8823feae77cb43a38197073de223f651"
     }
    },
    "aef3514475a54e5485aea6d9d23f5102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca8d5217d455418990a926645e71ac3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1fd3455cc1b4cfbba80191b71aef6c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e305ad027c664c7185e145cf1413f4d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e9b80fb0ed94718b52ef99fc95fa090",
      "placeholder": "​",
      "style": "IPY_MODEL_ca8d5217d455418990a926645e71ac3b",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
